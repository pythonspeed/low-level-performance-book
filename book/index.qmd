# Introduction {.unnumbered}

Your software is too slow.
Now what?

In many ways this depends on what kind of software you're writing: web applications, video games, and scientific computing all have different bottlenecks.
This book is specifically written for scientists, data scientists, and software developers who use Python to do numeric computing or data processing.

There are also many potential reasons your software might be slow.
This book limits itself to one particularly pervasive performance bottleneck: computation.
That is, the work your CPU does to calculate results, as well as related bottlenecks like memory.
I provide a quick review of the bigger picture of performance in the first chapter of the book, together with references to additional resources.

Assuming your performance bottleneck is computation, how do you speed it up?

## Optimizing Python-based data processing computation

Python[^cpython] is notoriously slow for computation, yet often used to handle large-scale data processing.
Getting faster results typically involves writing Python extensions in a fast, low-level, compiled language: C, C++, Fortran, Cython, Numba, Rust, and others.

There are many pre-written compiled extensions available as free libraries: NumPy, SciPy, Pandas, and Polars, to name just a few.
Typically they work by operating on batches of data—an array, or a dataframe.
Sometimes, however, preexisting libraries aren't fast enough, or aren't memory efficient enough, or simply don't implement the algorithms you need.
In that case you need to write your own computational code.

There are multiple ways to optimize computational code, i.e. making it run faster on a single CPU core:

1. Use scalable algorithms and data structures.
2. Avoid unnecessary and repetitive work.
3. If necessary, switch to a faster compiled language.

Once you make the switch to a compiled language, you can get even faster results by writing code that:

1. Enables the compiler to generate the fastest code possible, for example by avoiding aliasing.
2. Takes advantage of the sometimes unexpected ways modern CPUs work, from branch prediction to memory hierarchy.

This book will at least touch on all these techniques, in some cases going into much more depth.

## From optimized code to parallel code

Optimizing your code on a single CPU core is one way to get faster results.
Another is to use parallelism across multiple cores, something this book does not cover.

While you could jump straight to parallelism, optimization is still useful:

* Optimizing your code is multiplicative with parallelism: if you can make your code 10× faster on a single thread, and then 10× faster with parallelism, you will get results 100× faster.
* Both optimization and parallelism reduce electricity usage, and therefore carbon emissions; the reduction seems at least somewhat multiplicative.
* Unlike parallelism, optimization reduce the monetary costs of computing, since you get faster results without paying for more expensive hardware.

So really, you should be applying both techniques if possible.

Ready to get faster results from your code?
Let's get started!

[^cpython]: Technically, it's not the language that's slow, it's the default implementation. To distinguish the two, the Python interpreter is often known as CPython. The PyPy interpreter is a different implementation of the language that can do math much faster, but it adds overhead when interoperating with NumPy and other similar libraries, and lags behind on language features.
