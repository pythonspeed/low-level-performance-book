# Introduction {.unnumbered}

Your software is too slow.
Now what?

In many ways this depends on what kind of software you're writing: web applications, video games, and scientific computing all have different bottlenecks.
This book is specifically written for scientists, data scientists, and software developers who use Python to do numeric computing or data processing.

There are also many potential reasons your software might be slow.
This book limits itself to one particularly pervasive performance bottleneck: computation.
That is, the work your CPU does to calculate results, as well as related bottlenecks like memory.
I provide a quick review of the bigger picture of performance in the first chapter of the book, together with references to additional resources.

Assuming your performance bottleneck is computation, how do you speed it up?

## Optimizing Python-based data processing computation

Python[^cpython] is notoriously slow for computation, yet often used to handle large-scale data processing.
Getting faster results typically involves writing Python extensions in a fast, low-level, compiled language: C, C++, Fortran, Cython, Numba, Rust, and others.

There are many pre-written compiled extensions available as free libraries: NumPy, SciPy, Pandas, and Polars, to name just a few.
Typically they work by operating on batches of data—an array, or a dataframe.
Sometimes, however, preexisting libraries aren't fast enough, or aren't memory efficient enough, or simply don't implement the algorithms you need.
In that case you need to write your own Python extensions.

If you want fast code, using a compiled language is helpful, but not sufficient.
Regardless of your choice of programming language, you also need to:

1. Use scalable algorithms and data structures.
2. Avoid unnecessary and repetitive work.

In addition, once you make the switch to a compiled language, you can implement major performance improvements by learning more about both compiler and CPU behavior.
In particular, you can write code that:

1. Enables the compiler to generate even faster code, for example by avoiding aliasing.
2. Takes advantage of the sometimes unexpected ways modern CPUs work, from branch prediction to memory hierarchy.

We'll cover all of these in this book, focusing in particular on building a better mental model of compilers and CPUs, so you can write fast code from the start.

## Optimization and parallelism: you want both!

This book focuses on optimizing your code on a single CPU core.
But you can also use parallelism across multiple cores, something this book does not cover.

While you could jump straight to parallelism, optimization is still useful:

* The performance benefit of optimizing your code is multiplicative with parallelism: if you can make your code 10× faster on a single thread, and then 10× faster with parallelism, you will get results 100× faster.
* Both optimization and parallelism reduce electricity usage, and therefore carbon emissions; the reduction seems at least somewhat multiplicative.
* Unlike parallelism, optimization reduce the monetary costs of computing, since you get faster results without paying for more expensive hardware.

If possible, you should be applying both techniques.

Ready to get faster results from your code?
Let's get started!

[^cpython]: Technically, it's not the language that's slow, it's the default implementation. To distinguish the two, the Python interpreter is often known as CPython. The PyPy interpreter is a different implementation of the language that can do math much faster, but it adds overhead when interoperating with NumPy and other similar libraries, and lags behind on language features.
