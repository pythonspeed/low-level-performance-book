# Introduction {.unnumbered}

There are many kinds of software you can write: web applications, video games, scientific computing, and much more.
This book doesn't address all these types of software.
Instead, this book is specifically written for scientists, data scientists, and software developers who use Python to do numeric computing or data processing.

Even with that limited focus, there are still many potential reasons your software might be slow.
Your bottleneck might be computation, or network latency, or disk bandwidth.
Once again, this book won't cover all of these.
There are other books that cover performance from a much broader perspective than this one:

* [_High Performance Python, 2nd edition_](https://www.oreilly.com/library/view/high-performance-python/9781492055013/), by Gorelick and Oszvald.
  A third edition is in the works; I will likely be contributing a tiny section on Rust.
* [_Fast Python_](https://www.manning.com/books/fast-python), by Antao.

This book limits itself to one particular subset of the performance problem: computation.
In particular, I'm assuming that you have:

1. Determined that the speed of your code is a problem worth addressing.
2. Profiled your code to find the key bottleneck.
3. Discovered the bottleneck is computation, i.e. the amount of CPU time the code uses.
   If the bottleneck was something else, like network latency, this book won't help.

I do a quick review of this process, and the bigger picture of performance, in the first chapter of the book.

Assuming your performance bottleneck is computation, how do you speed it up?

## Speeding up Python-based data processing computation

Python[^cpython] is notoriously slow, but often used to handle large-scale data processing.
In order to do so in a reasonable amount of time, the solution has traditionally involved writing Python extensions in a fast, low-level, compiled language: C, C++, Fortran, Cython, Numba, Rust, and others.

There are many pre-written compiled extensions available as free libraries: NumPy, SciPy, Pandas, and Polars, to name just a few.
Typically they work by operating on batches of data—an array, or a dataframe.
Sometimes, however, preexisting libraries aren't fast enough, or aren't memory efficient enough, or simply don't implement the algorithms you need.

In that case, the common advice you'll get is:

1. Re-write your code in a compiled language.
2. Then, take advantage of parallelism, using multiple CPU cores.

Unfortunately, there's a key step missing in the middle of this process.

## The missing step: optimization

There's a better plan for speeding up your computational code:

1. Re-write your code in a compiled language.
2. **Optimize your code.**
   This is the bulk of what we'll focus on in this book.
3. Then, take advantage of parallelism, using multiple CPU cores.

Why not jump straight to parallelism?
It's true that optimization takes some of your time; you certainly don't want to waste time optimizing code that isn't a bottleneck.
However:

* Parallelism increases speed by increasing your financial costs.
  If my current computer is not fast enough and I want to run 10× faster locally using parallelism, I'd probably have to spend US$15,000 to buy a top of the line workstation.
  If I can optimize my code to run 10× faster—and this is often possible—I get that speedup without spending any money.
* Faster code is fundamentally better: you can iterate faster on improvements and bug fixes, you can run more experiments, you can handle more users.
  By utilizing both optimization and parallelism, you get the speed benefits of both.
* Finally, as you improve your optimization skills, you will start writing faster code from the start, with no extra time spent.

Ready to optimize your code?
Let's get started!

[^cpython]: Technically, it's not the language that's slow, it's the default implementation. To distinguish the two, the Python interpreter is often known as CPython. The PyPy interpreter is a different implementation of the language that can do math much faster, but it adds overhead when interoperating with NumPy and other similar libraries, and lags behind on language features.
