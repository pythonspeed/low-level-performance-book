# Avoid benchmarking with unrealistically small amounts of data

As we've seen in many of the previous chapters, a key to knowing whether you're making your code faster or slower is measurement.
However, if you use small amounts of data, the results can be misleading.
In this chapter we'll focus on one particular reason: memory caches.

Because your CPU has memory caches that are faster than RAM, but smaller in size, if you can keep data in those caches you will get higher performance.
Once your data gets larger, your process will end up using slower caches, or even RAM.
As a result, if the data you're benchmarking is much smaller than the the real data, your benchmarks may be inaccurate.

## Repeated benchmarks can hide 

Let's consider an example: we're going to calculate the sum of arrays of different sizes, and compare how long it takes.

```{python}
#| echo: false
%load_ext book_magics
```

```{python}
import numpy as np
from numba import njit

SMALL_DATA = np.arange(0, 1_000, dtype=np.uint64)
LARGE_DATA = np.arange(0, 10_000_000, dtype=np.uint64)

def flush_cache():
    print("Flushing memory caches...")
    # Create some garbage data large enough that it will hopefully clear out
    # any existing data from all CPU memory caches.
    data = np.arange(0, 10_000_000, dtype=np.uint64)
    del data
```

```{python}
GENERATOR = np.random.default_rng(0)

@njit
def random_sample(random_gen, arr):
    result = np.empty((10_000,), dtype=arr.dtype)
    for i in range(10_000):
        chosen_index = random_gen.integers(0, len(arr))
        result[i] = arr[chosen_index]
    return result

_ = random_sample(GENERATOR, np.array([1, 2], dtype=np.uint64))
```

```{python}
#| echo: false
%%compare_timing --measure=instructions
random_sample(GENERATOR, SMALL_DATA)
random_sample(GENERATOR, LARGE_DATA)
```

```{python}
@njit
def min_max_mean(arr):
    dtype_info = np.iinfo(arr.dtype)
    total = 0
    result_min = dtype_info.min
    result_max = dtype_info.max
    for i in range(len(arr)):
        value = arr[i]
        result_min = result_min if result_min < value else value
        result_max = result_max if result_max < value else value
        total += value
    return result_min, result_max, total / len(arr)

@njit
def min_max_mean_2(arr):
    dtype_info = np.iinfo(arr.dtype)
    total = 0
    result_min = dtype_info.min
    result_max = dtype_info.max
    for i in range(len(arr)):
        value = arr[i]
        result_min = result_min if result_min < value else value
    for i in range(len(arr)):
        value = arr[i]
        result_max = result_max if result_max < value else value
    for i in range(len(arr)):
        total += arr[i]
    return result_min, result_max, total / len(arr)

assert min_max_mean_2(SMALL_DATA) == min_max_mean(SMALL_DATA)
```

```{python}
#| echo: false
%%compare_timing
min_max_mean(SMALL_DATA)
min_max_mean(LARGE_DATA)
min_max_mean_2(SMALL_DATA)
min_max_mean_2(LARGE_DATA)
```
Next we'll create our summing function:

```{python}
@njit
def sum_array(arr):
    total = 0
    for i in range(len(arr)):
        total += arr[i]
    return total

assert sum_array(np.array([10, 2, 3], dtype=np.uint64)) == 15
```

Next, we'll measure how long it takes to sum `SMALL_DATA` and `DATA`.
We'll do the operation a few times in a row, then flush the cache and try again.

```{python}
from time import time

def timeit(f, *args):
    start = time()
    f(*args)
    print(f"{round((time() - start) * 1_000_000)} Âµs")
```

First, let's try with a small amount of data:

```{python}
flush_cache()
timeit(sum_array, SMALL_DATA)
timeit(sum_array, SMALL_DATA)
timeit(sum_array, SMALL_DATA)
flush_cache()
timeit(sum_array, SMALL_DATA)
```

Then, with a large amount of data:

```{python}
flush_cache()
timeit(sum_array, LARGE_DATA)
timeit(sum_array, LARGE_DATA)
timeit(sum_array, LARGE_DATA)
flush_cache()
timeit(sum_array, LARGE_DATA)
```

## More details about memory caches

To simplify somewhat, here's how the CPU talks to RAM:

```{dot}
digraph G {
  rankdir = "LR"
  node [shape = "box"]
  l1i [label="L1 cache (instructions)"]
  l1d [label="L1 cache (data)"]
  l2 [label="L2 cache"]
  l3 [label="L3 cache"]
  CPU -> l1i
  CPU -> l1d
  l1i -> l2
  l1d -> l2
  l2 -> l3 -> RAM
}
```

RAM is the slowest, L3 is a bit faster, L2 more so, and L1 is the fastest.
Typically L1 is per CPU core, L2 may or may not be per core, and L3 is shared across cores.
There are actually two L1 caches, one for instructions, i.e. the code you're running, and one for the data your program is using.

To give a sense of scale, the 8 physical performance (higher-speed) CPU cores in my i7-12700K have:

1. 48KiB L1 data cache and 32KiB L1 instruction cache for each core.
2. 1280KiB L2 cache for each core.
3. 25MiB L3 cache shared by all the cores, including both the performance cores plus the 4 lower-speed efficiency cores.

::: {.callout-note}
The `lstopo` command included in the [`hwloc`](https://www.open-mpi.org/projects/hwloc/) package can draw nice diagrams of your CPU's memory cache configuration.
:::
