# Reduce the cost of bounds checking

In addition to explicit branches you add to your code, there are other less obvious sources of branches: those that are automatically added by the compiler.
In this chapter we'll cover bounds checking, and in the next chapter we'll cover division by zero.

## Bounds checking adds performance overhead

Let's say you have an NumPy array of length 4, and you read the 5th item.
What happens?
There are two possible behaviors:

* **Error:** Some sort of error is raised, for example an `IndexError` Python exception.
* **Undefined behavior:** This can range from segfaults to corrupted data to completely arbitrary behavior.

You really want to get an error, not undefined behavior.
That means the compiler needs to check every location in the code where you read and write a given index.
In some cases the compiler will be able to detect your code is doing the wrong thing.
But most of the time it will add some extra code that checks _at runtime_ if the index is within bounds.

That is an extra branch being inserted into your code, and running every time you do a memory read or write.
It's a predictable branch, since only buggy code will do out-of-bounds reads or writes, but it will slow down your code.

Bounds checking behavior depends on the language you're using:

* C and C++ have no built-in bounds checking; they will happily corrupt memory or crash your program in the name of performance.
    However, some data structures will provide them, and more broadly you can use [sanitizers and other tools](https://developers.redhat.com/blog/2021/05/05/memory-error-checking-in-c-and-c-comparing-sanitizers-and-valgrind) to catch problems when testing your code.
* Numba and Cython (the latter with some caveats, since it compiles to C or C++) allow you to turn bounds checking on or off.
* Rust always has bounds checking on[^rust].

[^rust]: Technically Rust also has additional `unsafe` APIs to do lookups without bounds checking. Using `unsafe` is tricky, and misuse invalidates all of Rust's safety guarantees, so I would suggest pretending these APIs don't exist.

In Numba, bounds checking is disabled by default, but we can manually enable or disable it to compare the performance impact.
As an example we'll use a moving average function again, but this time we'll use zeros to fill in the missing first few values.

```{python}
#| echo: false
%load_ext book_magics
```

```{python}
import numpy as np
from numba import jit

DATA = np.random.random((1_000_000))

@jit(boundscheck=False)
def moving_average_no_bc(timeseries):
    result = np.empty(timeseries.shape, dtype=np.float64)
    for i in range(len(timeseries)):
        total = 0
        for j in range(max(i - 6, 0), i + 1):
            total += timeseries[j]
        result[i] = total / 7
    return result

# Same function, but bounds checks enabled:
@jit(boundscheck=True)
def moving_average_bc(timeseries):
    result = np.empty(timeseries.shape, dtype=np.float64)
    for i in range(len(timeseries)):
        total = 0
        for j in range(max(i - 6, 0), i + 1):
            total += timeseries[j]
        result[i] = total / 7
    return result

assert np.array_equal(
    moving_average_bc(DATA),
    moving_average_no_bc(DATA)
)
```

If we compare the two versions, the one with bounds checking is slower:

```{python}
#| echo: false
%%compare_timing --measure=instructions,branches
moving_average_bc(DATA)
moving_average_no_bc(DATA)
```

On the one hand, bounds checking is a great way to catch bugs, both in testing and production usage.
On the other hand, it slows down your code.
What can you do to balance safety and speed?

## Strategy #1: Enable bounds checking when testing, disable in production

If you don't want to enable bounds checking in production, you should at least enable it when running tests.
Combined with a thorough test suite, using both realistic data and property-based testing using [Hypothesis](https://hypothesis.readthedocs.io/), you can hopefully catch any bugs causing out-of-bounds reads or writes, and fix them.
If your code doesn't have bugs, disabling bounds checking in production isn't a problem.

That being said, decades of experience suggests that it is _very_ difficult to catch all such bugs once your software is complex enough.

## Strategy #2: Enable bounds checking everywhere, live with slower code

Quickly calculating the wrong answer is not very helpful.
As such, there's a strong argument to be made for always leaving bounds-checking enabled, even if this means a performance hit.

## Strategy #3: Help the compiler optimize bounds checking out of existence

In some cases you can leave bounds checking on, but provide enough information to the compiler that it will remove the bounds checks as part of its optimization passes.
This gives you the best of both worlds: the safety guarantees of bounds checking, without the performance cost.
This strategy is complex enough to merit its own chapter.
