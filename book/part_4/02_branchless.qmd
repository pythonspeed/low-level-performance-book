# Get rid of branches with branchless programming

One potential solution to the performance costs of branches is branchless programming, where we restructure code to get rid of branches altogether.

```{python}
import numpy as np
from numba import jit
```

```{python}
#| echo: false
%load_ext book_magics
```

## A simple example of branch misprediction

Let's see an example of code where branch misprediction slows down your code.

Imagine you're acquiring 16-bit images from a digital microscope, and you only care about the bright parts of the image.
Dark areas have no information, and have lots of noise.
To clean those areas up, a simplistic but often useful algorithm is setting all values below a certain threshold to complete darkness, i.e. 0.

To test our algorithms, let's generate two simulated images:

```{python}
rng = np.random.default_rng(12345)
noise = rng.integers(0, high=1000, size=(4096, 4096), dtype=np.uint16)
signal = rng.integers(0, high=5000, size=(4096, 4096), dtype=np.uint16)

# A noisy, hard to predict image:
NOISY_IMAGE = noise | signal

# An image with the same value, 0, for all pixels:
PREDICTABLE_IMAGE = np.zeros((4096, 4096), dtype=np.uint16)
```

Here's a first pass implementation:

```{python}
@jit
def remove_noise_naive(arr, noise_threshold):
    # Ensure noise_threshold has the same data type as the values in the arr,
    # to make it as easy as possible for the compiler to find optimizations.
    noise_threshold = arr.dtype.type(noise_threshold)
    result = arr.copy()
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            if result[i, j] < noise_threshold:
                result[i, j] = 0
    return result

denoised = remove_noise_naive(NOISY_IMAGE, 1000)
```

Notice that whether a specific pixel is above or below the noise threshold may be difficult to predict, depending on the image.
That is the case for `NOISY_IMAGE`.

Here's how long this version takes to run for both images:

```{python}
#| echo: false
%%compare_timing --measure=branches,branch_mispredictions
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_naive(NOISY_IMAGE, 1000)
```

The function runs with almost the same number of CPU instructions regardless of the image, it runs much more slowly with the unpredictable `NOISY_IMAGE`.
The key problem in the function above is the following lines:

```{python}
#| eval: false
if result[i, j] < noise_threshold:
    result[i, j] = 0
```

Depending on the value of `result[i, j]` either a value will be zeroed, or nothing will happen.
In other words, we have a branch in the code.
If the CPU mispredicts which branch is taken, it will using instruction-level parallelism to speculatively execute the _wrong branch_.
Eventually the branch will finish executing, the CPU will realize it made a bad prediction, and it will have to undo its work and then run the other branch.
All of this takes time, leading to slower execution.

### Switching to branchless programming

In this particular example, the branch is inherently difficult to predict for certain inputs.
So one way to run faster, or at least more predictably, is to avoid branches.

In branchless programming, we come up with a way to express the same logic in a way that doesn't involve branches.
In this case, instead of doing nothing, we can change the code so it _always_ writes a new value.
We use an arithmetic to trick to pick which value to write:

```{python}
@jit
def remove_noise_branchless_1(arr, noise_threshold):
    result = arr.copy()
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            # False/True becomes 0 or 1 respectively when converted to a
            # number:
            above_threshold = np.uint16(result[i, j] >= noise_threshold)
            # If we're above the threshold, we keep the value, otherwise
            # the expression evaluates to 0. ðŸ˜Ž Either way we're writing to
            # result[i, j], so there's no branch.
            result[i, j] = above_threshold * result[i, j]
    return result

assert np.array_equal(
    denoised,
    remove_noise_branchless_1(NOISY_IMAGE, 1000)
)
```

As an alternative, we can express the same thing with a ternary operator; in Numba, at least, the compiler is smart enough to turn this expression into non-branching code.

```{python}
@jit
def remove_noise_branchless_2(arr, noise_threshold):
    noise_threshold = arr.dtype.type(noise_threshold)
    result = arr.copy()
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            value = result[i, j]
            # ðŸ˜Ž Write to result[i, j] in either case, so there is no branch.
            result[i, j] = 0 if value < noise_threshold else value
    return result

assert np.array_equal(
    denoised,
    remove_noise_branchless_2(NOISY_IMAGE, 1000)
)
```

We'll focus on the ternary version just because it's easier to read.
Here's the difference in performance:

```{python}
#| echo: false
%%compare_timing --measure=branches,branch_mispredictions
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_naive(NOISY_IMAGE, 1000)
remove_noise_branchless_2(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_2(NOISY_IMAGE, 1000)
```

Notice that:

1. The branchless version is faster.
   This may or may not be the case, depending on the implementation.
2. The branchless version is consistent across images.
   This is the key advantage of branchless code: it doesn't lose performance due to branch misprediction.

The branchless function is seemingly doing more work: it writes to every pixel in the result image, not just some of them.
But that extra work is worth it, because it gets rid of an expensive branch misprediction.
Even better, it reduces the number of branches, probably by enabling the compiler to use SIMD more extensively.

### Bonus optimization: Getting rid of the copy

Now that we're overwriting all the values in the result, we don't actually have to copy the original image:

```{python}
@jit
def remove_noise_branchless_3(arr, noise_threshold):
    noise_threshold = arr.dtype.type(noise_threshold)
    # ðŸ˜Ž Use an empty array to begin with, since we will overwrite all values.
    result = np.empty(arr.shape, dtype=arr.dtype)
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            value = arr[i, j]
            result[i, j] = 0 if value < noise_threshold else value
    return result

assert np.array_equal(
    denoised,
    remove_noise_branchless_3(NOISY_IMAGE, 1000)
)
```

This version is even faster:

```{python}
#| echo: false
%%compare_timing --measure=branches,branch_mispredictions
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_naive(NOISY_IMAGE, 1000)
remove_noise_branchless_3(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_3(NOISY_IMAGE, 1000)
```

## Don't assume branchless programming is faster

Branchless programming is a trade-off: in return for getting rid of the potential cost of branch misprediction, you pay the guaranteed cost of calculating two or more branches, instead of just one.
That means branchless programming may well be slower, depending on how predictable your branch is, and how expensive the different branches are.
And that can depend on the specifics of your data.

In addition, SIMD auto-vectorization may or may not be happen depending on how the code is written.
If the right SIMD instructions are available and used, the compiler might be able to optimize branches out of existence, using "masked" operations where the SIMD instruction can be applied to only some of the data.

As always, it's critical to benchmark your code with real, or at least realistic, data that will match how the code will run in the real-world.
