# Get rid of branches with branchless programming

One potential solution to the performance costs of branches is branchless programming, where we restructure code to get rid of branches altogether.

```{python}
import numpy as np
from numba import njit
```

```{python}
#| echo: false
%load_ext book_magics
```

## A simple example of branch misprediction

Let's see an example of code where branch misprediction slows down your code.

Imagine you're getting 16-bit images from a digital microscope, and you only care about the bright parts of the image.
Dark areas have no information, and have lots of noise.
If we want to clean those areas up, a simplistic algorithm is setting all values below a certain threshold to complete black, i.e. 0.

To test our implementations, I generated two simulated images:

```{python}
rng = np.random.default_rng(12345)
noise = rng.integers(0, high=1000, size=(4096, 4096), dtype=np.uint16)
signal = rng.integers(0, high=5000, size=(4096, 4096), dtype=np.uint16)
# A noisy, hard to predict image:
NOISY_IMAGE = noise | signal
# An image with same value, 0, for all pixels:
PREDICTABLE_IMAGE = np.zeros((4096, 4096), dtype=np.uint16)
```

Here's a first pass implementation using Numba.

```{python}
@njit
def remove_noise_naive(arr, noise_threshold):
    # Ensure noise_threshold has some data type as the values in the arr,
    # to make it as easy as possible for the compiler to find
    # optimizations.
    noise_threshold = arr.dtype.type(noise_threshold)
    result = arr.copy()
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            if result[i, j] < noise_threshold:
                result[i, j] = 0
    return result

denoised = remove_noise_naive(NOISY_IMAGE, 1000)
```

Notice that whether a specific pixel is above or below the noise threshold may be difficult to predict, depending on the image.
That is certainly the case for our simulated image.

Here's how long this version takes to run:

```{python}
%%compare_timing --measure=branches,branch_mispredictions
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_naive(NOISY_IMAGE, 1000)
```

### Switching to branchless programming

The key problem in the function above is the following lines:

```{python}
#| eval: false
if result[i, j] < noise_threshold:
    result[i, j] = 0
```

Depending on the value of `result[i, j]` either a value will be zeroed, or nothing will happen: a branch in the code.
If the CPU mispredicts which branch is taken, it will end up wasting lots of time undoing work on the wrong branch.

In branchless programming, we come up with a way to express the same logic in a way that doesn't involve branches.
In this case, instead of doing nothing, we can change the code so it _always_ writes a new value.
We use an arithmetic to trick to pick which value to write:

```{python}
@njit
def remove_noise_branchless_1(arr, noise_threshold):
    result = arr.copy()
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            # false/true becomes 0 or 1 respectively when converted to a
            # number:
            above_threshold = np.uint16(result[i, j] >= noise_threshold)
            # If we're above the threshold, we keep the value, otherwise
            # the expression evaluates to 0. Either way we're writing to
            # result[i, j].
            result[i, j] = above_threshold * result[i, j]
    return result

assert np.array_equal(
    denoised,
    remove_noise_branchless_1(NOISY_IMAGE, 1000)
)
```

As an alternative, we can express the same thing with a ternary operator; for Numba, at least, the compiler is smart enough to turn this expression into non-branching code.

```{python}
@njit
def remove_noise_branchless_2(arr, noise_threshold):
    noise_threshold = arr.dtype.type(noise_threshold)
    result = arr.copy()
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            value = result[i, j]
            result[i, j] = 0 if value < noise_threshold else value
    return result

assert np.array_equal(
    denoised,
    remove_noise_branchless_2(NOISY_IMAGE, 1000)
)
```

Here's the difference in performance:

```{python}
#| echo: false
%%compare_timing --measure=branches,branch_mispredictions
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_naive(NOISY_IMAGE, 1000)
remove_noise_branchless_1(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_1(NOISY_IMAGE, 1000)
remove_noise_branchless_2(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_2(NOISY_IMAGE, 1000)
```

The two branchless versions are seemingly doing more work: they write to every pixel in the result image, not just some of them.
But that extra work is worth it, because it gets rid of an expensive branch misprediction.
Even better, it reduces the number of branches, probably by enabling to the compiler to use SIMD more extensively.

### Bonus optimization: getting rid of the copy

Now that we're overwriting all the values in the result, we don't actually have to copy the original image:

```{python}
@njit
def remove_noise_branchless_3(arr, noise_threshold):
    noise_threshold = arr.dtype.type(noise_threshold)
    result = np.empty(arr.shape, dtype=arr.dtype)
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            value = arr[i, j]
            result[i, j] = 0 if value < noise_threshold else value
    return result

assert np.array_equal(
    denoised,
    remove_noise_branchless_3(NOISY_IMAGE, 1000)
)
```

```{python}
#| echo: false
%%compare_timing --measure=branches,branch_mispredictions
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_naive(NOISY_IMAGE, 1000)
remove_noise_branchless_1(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_1(NOISY_IMAGE, 1000)
remove_noise_branchless_3(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_3(NOISY_IMAGE, 1000)
```

## Don't assume branchless programming is faster

Branchless programming is a trade-off: in return for getting rid of the cost of branch misprediction, you pay the cost of calculating two or more branches, instead of just one.
That means branchless programming may well be slower, depending on how predictable your branch is, and how expensive the different branches are.
And that can depend on the specifics of your data.

In addition, SIMD auto-vectorization may or may not be happen depending on how the code is written.
And if the right SIMD instructions are used, you won't have any branches, since the compiler might be able to use "masked" operations where the instruction can be applied to only some of the data.

As always, it's critical to benchmark your code with real, or at least realistic, data that will match how the code will run in the real-world.
