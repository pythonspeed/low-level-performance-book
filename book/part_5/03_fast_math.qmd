# Consider using your compiler's "fast math" mode

As we've discussed over the past few chapters, the compiler will be cautious about optimizing floating point code.
However, most compilers include a "fast math" option that tells the compiler that it is OK to optimize floating point calculations in ways that _do_ change the results.
If enabled, the compiler will apply optimizations it wouldn't otherwise be able to, hopefully resulting in faster code.

## An example: enabling fast math in Numba

```{python}
#| echo: false
%load_ext book_magics
```

Let's return to our original example, calculating volumes in liters:

```{python}
import numpy as np
from numba import jit

generator = np.random.default_rng(0)
# Containers are between 1 and 10 inches in each dimension:
SIZES_INCHES = generator.uniform(1, 10, (1_000_000, 3)).astype(np.float32)

@jit
def volume_liters(sizes):
    result = np.empty((sizes.shape[0],), dtype=np.float32)
    for i in range(sizes.shape[0]):
        width_in, height_in, depth_in = sizes[i]
        width_cm = width_in * 2.54
        height_cm = height_in * 2.54
        depth_cm = depth_in * 2.54
        result[i] = (width_cm * height_cm * depth_cm) / 1000.0
    return result

result = volume_liters(SIZES_INCHES)
```

We can compile this with Numba's fast math mode:

```{python}
@jit(fastmath=True)
def volume_liters_fm(sizes):
    result = np.empty((sizes.shape[0],), dtype=np.float32)
    for i in range(sizes.shape[0]):
        width_in, height_in, depth_in = sizes[i]
        width_cm = width_in * 2.54
        height_cm = height_in * 2.54
        depth_cm = depth_in * 2.54
        result[i] = (width_cm * height_cm * depth_cm) / 1000.0
    return result

result2 = volume_liters_fm(SIZES_INCHES)
```

If we compare the speed of the two, the fast math version is faster:

```{python}
#| echo: false
%%compare_timing
volume_liters(SIZES_INCHES)
volume_liters_fm(SIZES_INCHES)
```

We can also try benchmarking our manually optimized version and a fast math equivalent.

```{python}
@jit
def volume_liters_3(sizes):
    result = np.empty((sizes.shape[0],), dtype=np.float32)
    in3_to_liter = (2.54 * 2.54 * 2.54) / 1000
    for i in range(sizes.shape[0]):
        width_in, height_in, depth_in = sizes[i]
        result[i] = width_in * height_in * depth_in * in3_to_liter
    return result

@jit(fastmath=True)
def volume_liters_3_fm(sizes):
    result = np.empty((sizes.shape[0],), dtype=np.float32)
    in3_to_liter = (2.54 * 2.54 * 2.54) / 1000
    for i in range(sizes.shape[0]):
        width_in, height_in, depth_in = sizes[i]
        result[i] = width_in * height_in * depth_in * in3_to_liter
    return result

_ = volume_liters_3(SIZES_INCHES)
_ = volume_liters_3_fm(SIZES_INCHES)
```

In this case, the compiler can't improve on the manual optimizations we've already done, so fast math mode adds no performance benefit:

```{python}
#| echo: false
%%compare_timing
volume_liters_3(SIZES_INCHES)
volume_liters_3_fm(SIZES_INCHES)
```

## Avoid full fast math mode

Enabling fast math in your compiler typically results in enabling multiple different optimizations, with different effects.
For example, Numba and the clang C/C++ compiler can enable all or some of [LLVM's fast math transformations](https://llvm.org/docs/LangRef.html#fast-math-flags).
One transformation allows replacing division with multiplication by the reciprocal, which is fairly innocuous.
But another assumes you will never have a `NaN` in your calculation results; if you do, you will trigger undefined behavior.

Even worse, on Linux older versions of `gcc` and all versions of `clang` have a bonus behavior where linking in fast math mode will link in extra code that can break _other_ Python extensions.
[See this blog post for the details](https://moyix.blogspot.com/2022/09/someones-been-messing-with-my-subnormals.html).
GCC 13 fixed this behavior, but [LLVM/`clang` have not](https://github.com/llvm/llvm-project/issues/57589).

Given these potentially undesirable side-effects, it's likely better to only enable specific fast math optimizations, rather than enabling all of them.
How you do so is different for each compiler.
Here's how you'd do it in Numba using the [LLVM-specific list of optimizations](https://llvm.org/docs/LangRef.html#fast-math-flags):

```{python}
@jit(fastmath={"nsz", "arcp", "contract", "afn", "reassoc"})
def volume_liters_fm_explicit(sizes):
    result = np.empty((sizes.shape[0],), dtype=np.float32)
    for i in range(sizes.shape[0]):
        width_in, height_in, depth_in = sizes[i]
        width_cm = width_in * 2.54
        height_cm = height_in * 2.54
        depth_cm = depth_in * 2.54
        result[i] = (width_cm * height_cm * depth_cm) / 1000.0
    return result

_ = volume_liters_fm_explicit(SIZES_INCHES)
```

Here's how it runs:

```{python}
#| echo: false
%%compare_timing
volume_liters_fm(SIZES_INCHES)
volume_liters_fm_explicit(SIZES_INCHES)
```
