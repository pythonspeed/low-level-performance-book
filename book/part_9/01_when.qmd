# When is a low-level compiled language useful?

So far we've been focusing on how building a mental model of how to write faster compiled code.
Starting with this chapter we'll focus on applying this knowledge in practice, for real code that needs to be optimized.

To begin with, just because your code is slow to run doesn't mean rewriting in a low-level compiled language is the way to speed it up.
In many cases that rewrite will be a waste of your time, with little or no benefit.
So before going down that route—the topic of the rest of this book—it's important to understand that other bottlenecks exist, and some hints on how to identify when rewriting your code is actually necessary.

```{python}
#| echo: false
%load_ext book_magics
```

## Identifying bottlenecks with a profiler

The starting point to optimizing your code is figuring out why it's slow.
By using one of the many performance profilers for Python—cProfile, PySpy, Austin, PyInstrument, VizTracer, and many more—you can identify which parts of your code are taking the most time.
If you've never used a profiler before, running [`line_profiler`](https://pypi.org/project/line-profiler/) on a function is probably the easiest one to get started with profiling.

Some profilers—like the [Sciagraph profiler](https://sciagraph.com) I created—can tell you whether that code was spending it's time waiting or doing computation.
In other cases you'll need to figure it out from context: if you're spending all your time reading from a file or waiting for a result from PostgreSQL, that's probably not going to be solved by faster computation!x

## Non-computational performance bottlenecks

If your code is just waiting, rewriting it in a lower-level compiled language is unlikely to help.
Here are just some of the reasons your code might just sit around doing nothing.

### Waiting for a remote service

In many web applications, the database is the key performance bottleneck in the backend.
To speed things up, you'll need to optimize the query, add an index, tune the database, and so on.

### Network latency and bandwidth

Your program may end up spending much of its time reading and writing over the network.
This can be due to bandwidth limitations: you can download at 10MB/sec, and you're downloading a 5000MB file.

Or, the bottleneck may be due to latency, the time it takes to send a message to the remote server.
Imagine you're downloading 100,000 files of 1KB each, sequentially.
If the latency of a download, the time to get a response, is 1 milliseconds, it will take you 100 seconds to download all the files.
The bandwidth you use will only be 1MB/second.
If your maximum download speed is 100MB/sec, switching to one giant download will allow you to download the file in 1 second, 100× faster.

### Reading and writing from disk

Like the network, reading and writing from disk can suffer both from slowness caused by both bandwidth and latency.
The bandwidth from a local disk can be quite higher, and the access speed is much faster so latency is lower, but this can still be a bottleneck.

### Swapping

What happens when your data doesn't fit in RAM?
For example, your computer may have 64GB of RAM (i.e. memory), but you have 120GB of data you've loaded into your running program.

In these situations, the operating system will move some memory out of RAM and on to disk; this is known as swapping.
If you swap out data you aren't currently using, this won't be noticeable.
But if you are continuously accessing more data than fits in RAM, it will be continuously moved back and forth from disk.
Beyond a certain point your whole computer will grind to a halt as it spends all its time trying to move data back and forth between disk and RAM.

## Computational bottlenecks you might be able to solve with just Python

Even if the bottleneck in your program is computation, there might be ways you can fix it just by tweaking your Python code.
Elsewhere in the book we cover making your code more efficient, but there are some library-specific issues you might also encounter.

### Not using vectorization

Libraries like NumPy, SciPy, Pandas and others can process data very quickly by doing batch processing in functions implemented in a low-level language like C or Fortran.
This is known as "vectorization".

In general, avoid using `for` loops and other similar constructs like list comprehensions on large NumPy arrays.
If you have such a loop in your code, switching to a vectorized API can give you a significant speed-up, without having to switch away from Python.
For example:

```{python}
import numpy as np

def sum_with_for_loop(arr):
    total = 0
    for value in arr:
        total += value
    return total

def sum_vectorized(arr):
    return arr.sum()

ARR = np.ones((1_000, 1_000), dtype=np.int64)
```

If we time the two functions, the `for` loop is much slower:

```{python}
#| echo: false
%%compare_timing
sum_with_for_loop(ARR)
sum_vectorized(ARR)
```

## Sometimes Python is not enough

Sometimes none of the situations above apply, and you really do need to abandon Python and switch to lower-level compiled code.

### Case 1: The vectorized implementation uses too much memory

Vectorized APIs operate on complete arrays.
That means when you create temporary intermediate values, they will also have to be arrays.
The result is that you often have gigantic temporary arrays using massive amounts of memory.

You can reduce this massive memory usage overhead by doing the operation in chunks or batches, so the temporary arrays are smaller.
Or, you can switch to a lower-level language and then use a `for` loop to iterate over individual values is fast enough.
This means temporary values can be tiny, instead of gigantic, saving you lots of memory.

### Case 2: The vectorized implementation is too slow

Sometimes the vectorized implementation is just too slow.
If you want an optimized version, you're going to have to implement it with lower-level code, where you have more control over how the code runs.

### Case 3: The algorithm can't be expressed with vectorized operations

Sometimes you _can't_ implement the algorithm with existing vectorized APIs.
When this happens, the only solution is to implement a new vectorized API with low-level code.
This is why libraries like SciPy have so much low-level compiled code: the building blocks in NumPy aren't always sufficient.
