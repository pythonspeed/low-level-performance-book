# Reduce the costs of branch misprediction

`if` statements, `for` loops, `while` loop, and other less obvious code structures can result in branches in your code.
Branches can have an unexpected performance impact at runtime, due to interactions with instruction-level parallelism (ILP).
As we discussed in a previous chapter, ILP allows the CPU to run multiple instructions in parallel if it knows they don't depend on each other.

Branches present a problem for ILP: given there are two possible sets of future instructions, for example the two branches of an `if` statement, how can the CPU know which set it should be executing in parallel?

Instead of just stopping execution until the `if` statement can be calculated, the CPU will instead make a guess, a "branch prediction."
Based on this prediction, the CPU speculatively keeps executing code in parallel _as if_ that prediction is correct.

* If the chosen branch turns out to be correct, all is well, and your code will run faster.
* If the guess turns out to be wrong‚Äîa branch misprediction‚Äîthen the work done so far has to be undone.
  And that can slow down your code significantly.

In practice, many conditionals have very consistent answers for long stretches of time, in which case branch prediction will end up being very accurate, and this effect won't impact your code.
Consider a `for` loop over a large array: the conditional that checks whether you've hit the end of the array will be very predictable.

The main performance issue you need to worry about, then, is when branches are unpredictable.

## Example: The cost of branch misprediction

Imagine you're acquiring 16-bit images from a digital microscope, and you only care about the bright parts of the image.
Dark areas have no information, and have lots of noise.
To clean those areas up, a simplistic but often useful algorithm is setting all values below a certain threshold to complete darkness, namely 0.

To test the algorithm, I will generate two simulated images:

```{python}
# For educational purposes, tell Numba to disable SIMD, so it doesn't hide
# other effects:
import os
os.environ["NUMBA_LOOP_VECTORIZE"] = "0"
os.environ["NUMBA_SLP_VECTORIZE"] = "0"

import numpy as np
from numba import jit

rng = np.random.default_rng(12345)
noise = rng.integers(0, high=1000, size=(4096, 4096), dtype=np.uint16)
signal = rng.integers(0, high=5000, size=(4096, 4096), dtype=np.uint16)

# A noisy, hard to predict image:
NOISY_IMAGE = noise | signal

# An image with the same value, 0, for all pixels:
PREDICTABLE_IMAGE = np.zeros((4096, 4096), dtype=np.uint16)
```

```{python}
#| echo: false
# Important to do this _after_ setting NUMBA_LOOP_VECTORIZE.
%load_ext book_magics
```

Here's a first pass implementation:

```{python}
@jit
def remove_noise_naive(arr, noise_threshold):
    # Ensure noise_threshold has the same data type as the values in the arr,
    # to make it as easy as possible for the compiler to find optimizations.
    noise_threshold = arr.dtype.type(noise_threshold)
    result = arr.copy()
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            # üôÅ Depending on the input data, this branch may be difficult to
            # predict.
            if result[i, j] < noise_threshold:
                result[i, j] = 0
    return result

denoised = remove_noise_naive(NOISY_IMAGE, 1000)
```

Notice that whether a specific pixel is above or below the noise threshold may be difficult to predict, depending on the image.
That is the case for `NOISY_IMAGE`.

Here's how long this version takes to run for both images:

```{python}
#| echo: false
%%compare_timing --measure=branches,branch_mispredictions
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_naive(NOISY_IMAGE, 1000)
```

The function runs with almost the same number of CPU instructions regardless of the image.
However, it runs much more slowly with the unpredictable `NOISY_IMAGE`.
The key problem in the function above is the following lines:

```{python}
#| eval: false
if result[i, j] < noise_threshold:
    result[i, j] = 0
```

Depending on the value of `result[i, j]` either a value will be zeroed, or nothing will happen.
In other words, we have a branch in the code.
If the CPU mispredicts which branch is taken, it will using instruction-level parallelism to speculatively execute the _wrong branch_.
Eventually the branch will finish executing, the CPU will realize it made a bad prediction, and it will have to undo its work and then run the other branch.
All of this takes time, leading to slower execution.

## Replace unpredictable branches with branchless programming

In the example above, the branch is inherently difficult to predict for certain inputs.
So one way to run faster, or at least more predictably, is to avoid branches.

In branchless programming, we come up with a way to express the same logic in a way that doesn't involve branches.
In this case, instead of doing nothing, we can change the code so it _always_ writes a new value.

We use an arithmetic to trick to pick which value to write:

```{python}
@jit
def remove_noise_branchless_1(arr, noise_threshold):
    result = arr.copy()
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            # False and True become 0 and 1 respectively when converted to a
            # number:
            above_threshold = np.uint16(result[i, j] >= noise_threshold)
            # üòé If we're above the threshold, we keep the value, otherwise
            # the expression evaluates to 0. Either way we're writing to
            # result[i, j], so there's no branch.
            result[i, j] = above_threshold * result[i, j]
    return result

assert np.array_equal(
    denoised,
    remove_noise_branchless_1(NOISY_IMAGE, 1000)
)
```

As a more readable alternative, we can express the same thing with a ternary operator; in Numba, at least, the compiler is smart enough to turn this expression into non-branching code.
This is still branchless, though, because unlike the original version the code writes to `result[i, j]` in both cases.
Previously it only wrote values that were being thresholded down to zero.

```{python}
@jit
def remove_noise_branchless_2(arr, noise_threshold):
    noise_threshold = arr.dtype.type(noise_threshold)
    result = arr.copy()
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            value = result[i, j]
            # üòé Write to result[i, j] in either case, so there is no branch.
            result[i, j] = 0 if value < noise_threshold else value
    return result

assert np.array_equal(
    denoised,
    remove_noise_branchless_2(NOISY_IMAGE, 1000)
)
```

I'll focus on the ternary version just because it's easier to read.
Here's the difference in performance:

```{python}
#| echo: false
%%compare_timing --measure=branches,branch_mispredictions
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_naive(NOISY_IMAGE, 1000)
remove_noise_branchless_2(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_2(NOISY_IMAGE, 1000)
```

Notice that:

1. The branchless version is about the same speed as the original implementation's best case.
   This may or may not be the case, depending on the implementation: it could also be faster or slower.
2. The branchless version has fewer branches, and much less branch misprediction.
3. The branchless version takes a consistent amount of time to process different images.
   This is the key advantage of branchless code.

The branchless function is seemingly doing more work: it writes to every pixel in the result image, not just some of them.
But that extra work is worth it, because it gets rid of an expensive branch misprediction.

### Bonus optimization: Getting rid of the copy

Now that we're overwriting all the values in the result, we don't actually have to copy the original image:

```{python}
@jit
def remove_noise_branchless_3(arr, noise_threshold):
    noise_threshold = arr.dtype.type(noise_threshold)
    # üòé Use an empty array to begin with, since we will overwrite all values.
    result = np.empty(arr.shape, dtype=arr.dtype)
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            value = arr[i, j]
            result[i, j] = 0 if value < noise_threshold else value
    return result

assert np.array_equal(
    denoised,
    remove_noise_branchless_3(NOISY_IMAGE, 1000)
)
```

This version is even faster:

```{python}
#| echo: false
%%compare_timing --measure=branches,branch_mispredictions
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_naive(NOISY_IMAGE, 1000)
remove_noise_branchless_3(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_3(NOISY_IMAGE, 1000)
```


## Understand what constitutes a branch

A branch in your code is a place where two different CPU instructions might end up running.
Consider the following example‚Äîdepending on the value of `x`, execution will take different paths through the function, executing different code:

```{python}
#| echo: false
%load_ext book_magics
```

```{python}
import numpy as np
from numba import jit

@jit
def abs(x):
    if x > 0: # <-- this is a branch
        x = -x
    return x
```

Merely having a conditional expression doesn't mean the code is a branch; the key is executing different CPU instructions depending on the conditional.
For example, the following function does not have a branch:

```python
@jit
def abs_branchless(x):
    # is_negative will be either 0 or 1:
    is_negative = np.int64(x > 0)  # <-- this is NOT a branch
    # choose appropriate multiplier:
    multiplier = (1, -1)[is_negative]
    # convert x to a positive version:
    return x * multiplier
```

But the following function does have a branch, because the `while` may or may not continue in each iteration:

```python
@jit
def loop(x):
    while x > 0: # <-- this is a branch
        x = transform(x)
    return x
```

## Don't assume branchless programming is faster

Branchless programming is a trade-off: in return for getting rid of the potential cost of branch misprediction, you pay the guaranteed cost of calculating two or more branches, instead of just one.
That means branchless programming may well be slower, depending on how predictable your branch is, and how expensive the different branches are.
And that can depend on the specifics of your data.

In addition, SIMD auto-vectorization may or may not be happen depending on how the code is written.
If the right SIMD instructions are available and used, the compiler might be able to optimize branches out of existence, using "masked" operations where the SIMD instruction can be applied to only some of the data.

As always, it's critical to benchmark your code with real, or at least realistic, data that will match how the code will run in the real-world.
