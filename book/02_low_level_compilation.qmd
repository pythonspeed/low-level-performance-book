# Speeding up your code with low-level compilation

What do I mean by a low-level compiled language?

1. The code is converted ("compiled") to machine code before it is run.
   Machine code is the set of binary instructions your CPU runs: the resulting code runs directly on the CPU.
2. Each variable has a specific type that is known at compile time.
   It might be a 64-bit integer, it might be something more complex, but this information is available to the compiler.

Examples include C, C++, Rust, Fortran, and Numba.
Cython compiles to C or C++, and then that code is compiled to machine to code, so it counts too.

In contrast, CPython, the default Python implementation:

1. Does not currently generate machine code, though work is in progress for future versions.
2. Does not necessarily know what type a variable is.

> In theory, type hints give CPython more information, but in practice they are not currently used.
> Even if they were, they're hints: even if the function claims it accepts integers, you could still pass it floats if you wanted to.

These differences allow low-level compiled languages to do certain operations much more quickly than Python.

## Python vs. a low-level compiled language

Let's look at an example: a function that adds two parameters and returns the result.

Here's a Python function:

```{python}
def add(a, b):
    return a + b
```

And here's a similar Rust function:

```rust
fn add(a: i64, b: i64) -> i64 {
    a + b
}
```

On the face of it they are quite similar: you can add two integers with one or the other.
But dig into the implementation and you get a very different perspective.

The Rust code is compiled directly to machine code.
Here's the x86-64 assembly generated for this function:

```assembly
lea     rax, [rdi + rsi]
ret
```

You don't need to understand what `lea` or `ret` do.
The important point here is that this function is just two machine code instructions, a trivial amount of work.
There's a reason Rust has `i64` as a built-in numeric type: most CPUs you are likely to encounter have built-in support for math on 64-bit integers.

Next, let's consider what happens when you call the Python function.
First, the Python interpreter that is running your code may not know what type the passed in objects are, so it needs to inspect the types of `a` and `b` to figure out what add function to use.
This already takes more effort than the two CPU instructions above.

In this case, for two integers, Python will eventually call the C function `_PyLong_Add`.
Here's what it looks like:

```c
PyObject *
_PyLong_Add(PyLongObject *a, PyLongObject *b)
{
    if (IS_MEDIUM_VALUE(a) && IS_MEDIUM_VALUE(b)) {
        return _PyLong_FromSTwoDigits(medium_value(a) + medium_value(b));
    }

    PyLongObject *z;
    if (Py_SIZE(a) < 0) {
        if (Py_SIZE(b) < 0) {
            z = x_add(a, b);
            if (z != NULL) {
                /* x_add received at least one multiple-digit int,
                   and thus z must be a multiple-digit int.
                   That also means z is not an element of
                   small_ints, so negating it in-place is safe. */
                assert(Py_REFCNT(z) == 1);
                Py_SET_SIZE(z, -(Py_SIZE(z)));
            }
        }
        else
            z = x_sub(b, a);
    }
    else {
        if (Py_SIZE(b) < 0)
            z = x_sub(a, b);
        else
            z = x_add(a, b);
    }
    return (PyObject *)z;
}
```

Notice how it might be calling other functions, like `medium_value()` and `x_add()`.
Why so complex?
For one thing, whereas the Rust integers are 64-bit, Python integers are unlimited in size.
As a result:

* Where C or Rust 64-bit integers are just an 8-byte value that the CPU already understands, Python integers are a much more complex object that takes a minimum of 28 bytes, but can be more.
* Since the CPU doesn't understand how to add these more complex objects, Python has to convert it back down to low-level values the CPU does understand, do the math, and then create a new `PyLongObject*` with the result.

Put this all together, and doing basic math in Python can be two orders of magnitude slower than doing math in C or Rust.

## Compiler optimizations: the good, bad, and ugly

A compiler takes the code you've written and turns it into machine code that your CPU can run.
If that code is constrained—adding only 64-bit integers, instead of any arbitrary pair of objects as in Python—the resulting code will do less work and run faster.

But a compiler does more than just translating your code: it also _optimizes_ your code.
In particular, the compiler will run your code through a series of transformations that will (hopefully) make your code run faster.

There's just one constraint on these optimization passes: the resulting program must behave as if it was exactly the same code you've written.
What are the consequences of constraining the compiler output to identical behavior?

* **The good:** You don't have to worry about your code's behavior changing, even as it becomes faster with no work on your part.
* **The bad:** Some optimizations that might seem obvious to you won't happen, if the compiler decides that the resulting behavior might be slightly different.
  Even if the difference is something you don't care about, the compiler has no way of knowing that, and it will err on the side of conservatism.
* **The ugly:** The guarantee of identical behavior only applies to code that the compiler considers to be well-defined.
  In Rust, so long as you don't use the `unsafe` keyword, all your code has well-defined behavior, so you don't have to worry about this.
  In other languages, and especially C, there are _many_ ways to write code that the compiler will happily compile, but which does something the compiler considers impossible.
  Since it's doing the impossible, the compiler's assumptions when optimizing might be very wrong, and the result will be completely unexpected behavior by the compiled program, from crashes to corrupted data or worse.

We'll talk about the first two in the next chapter, and about undefined behavior in a later chapter.

## Connecting low-level code to Python

This book is aimed at Python developers, with the assumption you're probably going to use Python code to interact with any low-level code you write.
That adds a wrinkle: you need to get data back and forth from Python to the low-level language.
This adds overhead and complexity.
For example, if we're passing arguments from Python to the low-level language:

* As we've seen above, Python's representation of integers allows for arbitrarily-sized values, whereas low-level programming languages typically operate on 8-bit, 16-bit, 32-bit, or 64-bit integers.
* A Python list can contain multiple different types, for example `[1, "hello", 2.3]`; you can't just assume all the items are integers, for example.
  Handling this sort of data structure involves using the Python C APIs to introspect each item, which is expensive.

As a result, converting a Python list of integers to a C array or Rust vector of integers would involve some relatively expensive code, before you've even started implementing any of the logic you need.
And when moving the data back to the Python in the other direction, the same problem applies, doubling the cost.

The solution is to use data structures designed to allow efficient access from low-level languages while still allowing access from Python.
For example:

* NumPy arrays have a specific data type, for example a 64-bit signed integer, and internally are created as a contiguous array.
That means low-level code can access the items in a NumPy array with dtype `np.int64` just like it would any array of 64-bit signed integers: very quickly.
* Older versions of Pandas used NumPy arrays internally, and newer versions still support this format for now.
* Polars (always) and Pandas 2 (for now optionally) use Apache Arrow, which is a data structure designed for efficient access from low-level languages.
  There are Arrow implementations for C++, Rust, and other languages, and it can also be used from Cython.

For both NumPy arrays and Apache Arrow, as well as other data structures designed with this use case in mind, the cost of transferring between Python and the low-level language is negligible.
In this book we'll mostly use example involving NumPy arrays, but the same principles apply to any data structure that can be cheaply passed between Python and low-level languages.

