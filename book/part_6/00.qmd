# Make memory access more efficient

So far we've been mostly ignoring memory reads and writes, essentially assuming that they're fairly fast and take a consistent amount of time to run.
Neither assumption is always true, so a more accurate mental model can help you speed up our code.

As it turns out, from a CPU's perspective, reading from RAM—the active memory of the computer—is actually quite slow.
To speed things up, CPU designers provide a series of caches to reduce the need to access RAM.
Recently used data is stored in those caches, and that speeds up memory access... for data that is already in the cache.
If the data you need isn't in a fast cache, you might end up with a slow memory read from RAM.

That means memory access is sometimes fast, and sometimes slow.
Fast code will keep these caches in mind in order to achieve consistently fast access.
