## Scan N-dimensional arrays in a linear fashion

As we saw in a previous chapter, scanning memory linearly is the fastest way to do so.
Whether or not you're scanning memory linearly becomes a little less obvious when you're dealing with N-dimensional arrays: the memory address space is linear, so there's different ways to map the different dimensions on.
Imagine the following array:

```
  X →
Y 1, 2, 3
↓ 4, 5, 6
```

It could be laid out in memory like this:

```
1, 2, 3, 4, 5, 6
```

Or like this:

```
1, 4, 2, 5, 3, 6
```

However it's laid out, we want to iterate over the data in a way that matches that layout, because that will be faster.
In practice, NumPy arrays by default will be laid out so the last dimension is contiguous in memory, so you want to iterate over the dimensions in order, from first to last.
Let's see an example:

```{python}
#| echo: false
%load_ext book_magics
```

```{python}
import numpy as np
from numba import jit

two_d = np.ones((2_000, 2_000), dtype=np.int64)

@jit
def scan_y_first(arr):
    total = 0
    for y in range(arr.shape[0]):
        for x in range(arr.shape[1]):
            total += arr[y, x]
    return total

@jit
def scan_x_first(arr):
    total = 0
    for x in range(arr.shape[1]):
        for y in range(arr.shape[0]):
            total += arr[y, x]
    return total

assert scan_y_first(two_d) == scan_x_first(two_d)
```

Given NumPy's default memory layout, scanning the dimensions in order is faster, because that matches how NumPy arrays are laid out in memory:

```{python}
#| echo: false
%%compare_timing --measure=instructions,l1_memory_cache_miss
scan_y_first(two_d)
scan_x_first(two_d)
```

There are two notable differences in these results:

1. As expected, scanning memory in linear order results in far fewer cache misses.
2. The number of CPU instructions is much lower.
   We'll get a better sense of why this is the case in the next chapter.

