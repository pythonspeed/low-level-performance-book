---
title: "Use faster algorithms and data structures"
---

In the previous chapter you saw the importance of using more _scalable_ algorithms and data structures.
For example, given a sufficiently large $n$, a $O(n^2)$ algorithm will be much slower than a $O(n)$ algorithm.

Scalability on its own is not enough for software to be fast.
If two functions have $O(n)$ scalability, that means that for both functions doubling $n$ will double their run time.
But it doesn't tell you anything about their speed relative to each other; one may be much faster than the other.

In short, looking at scalability is insufficient: you also need to see how fast the implementation is.

```{python}
#| echo: false
%load_ext book_magics
```

## For small key ranges, consider a vector (Python `list`) instead of a hash map (Python `dict`)

Consider two commonly used data structures:

* Reading and writing values from/to a hash map like Python's `dict` type is an amortized $O(1)$: on average it's constant time.
  In practice most of the time you can ignore the "amortized" part, as I will in this chapter[^bulk].
* Reading and writing values from/to indexes in a vector like Python's `list` type is $O(1)$: it's constant time.

[^bulk]: In general, this book focuses on the bulk data processing, so the latency of a specific operation doesn't matter.

If you have a small range of integer values, you can use one or the other.
For example, imagine you have a list of all the grades for a standardized test administered to high school students across a city or country.
Each grade can be between 1 and 100.
You need to make a histogram of grades with 10 equal buckets.
Here are two implementations, one with `dict` and one with `list`:

```{python}
def histogram_dict(grades):
    histogram = {
        bucket: 0 for bucket in range(10)
    }
    for grade in grades:
        bucket = (grade - 1) // 10
        histogram[bucket] += 1
    return histogram

def histogram_list(grades):
    histogram = [0] * 10
    for grade in grades:
        bucket = (grade - 1) // 10
        histogram[bucket] += 1

    # Convert into a dict to match the output of histogram_dict():
    return {
        bucket: histogram[bucket] for bucket in range(10)
    }
```

Both implementation give the same result:

```{python}
import random

# Generate 10,000 random grades:
GRADES = [random.randint(1, 100) for _ in range(10_000)]

assert histogram_dict(GRADES) == histogram_list(GRADES)
```

And both implementations are $O(n)$, where $n$ is the number of grades.
Which one will be _faster_?

`histogram_list()` will be faster.
To read or write from a key, the `dict` hashed the key into an integer, map that to internal vector within the `dict`, and do an equality comparison.
If you're unlucky, it will have to do some or all of these operations multiple times.
In contrast, when indexing into a `list`, there is no need to do any of those preliminary steps, so there's less work involved.

Measuring the actual performance, you can see that `histogram_list()` is faster:

```{python}
#| echo: false
%%compare_throughput --unit=grades:len(GRADES)
histogram_dict(GRADES)
histogram_list(GRADES)
```

In a compiled language I would expect the difference to be even larger.
