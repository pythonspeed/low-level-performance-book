# Create realistic end-to-end benchmarks

Speed is a property of your whole program: from the moment it starts until the moment it ends.
If you optimize part of the code that takes up 10% of the time, and make it take 20% less time to run, your overall program's speed is improved by 2%.
That's not _bad_, but it may not be a good use of your time.

As a result, before optimizing smaller parts of your program, it's useful to create benchmark for measuring performance that matches your program's end-to-end speed.
That is, run your program with real data, and see how fast it is.
Given such a benchmark, you can:

* Identify _which_ parts of the code are responsible for slowness, so you can focus on those.
  I'll discuss that in the next chapter on profiling.
* Measure the speed of your code for different inputs, to see if certain inputs result in worse performance.
* See how the speed of your code changes over time, as you make changes.

## Make sure your benchmark is realistic

The speed you care about is the speed of your code running in the real world.
So if you're creating a benchmark, you want to make sure it matches the real world as much as possible.
In practice this may be difficult, so you may need to compromise and do your best.
But in so far as possible—or, in your best judgment, relevant—you'll want to use:

* The same hardware.
* The same dependency versions.
* The same configuration.
* Real-world data.

## Measure in production

If you are already using your code in the real world, you have another option.
Instead of trying to match the way your code runs in a duplicate setup, you can just measure speed in those real-world production runs.
This gives you less control, but results that aren't just 100% realistic, but actually real.

Options here include:

* Continuous profiling, i.e. running a profiler in production.
  The next chapter discusses profiling more broadly, but beyond that there are services that do continuous profiling.
  Most of these services are designed for web applications, so if you're profiling a batch job they won't give you everything you'd want.
  [Sciagraph](https://sciagraph.com) is my attempt to make a continuous profiling system for batch jobs like data science or scientific computing..
* Logging, or even better tracing—a form of logging where you create a tree of messages.
  [See this article](https://pythonspeed.com/articles/slow-data-analysis-tasks/) for an example.

One thing to keep in mind is whether your hardware is actually consistent across runs.
In a cloud environment, different virtual machines of the same class might use different CPUs, and therefore have inconsistent performance.
As a result, changes over time might not be as informative as one might hope.

## Choose an appropriate speed metric

Once you have a benchmark, you can measure how fast your code is, both over time as the code changes, and for different inputs.
As an example, imagine you're working on a geocoding service, that turns addresses into latitude/longitude pairs.
There are two ways to use the service:

* An individual API where a customer sends a single address, and gets back its location.
* A bulk API where a customer uploads a CSV with many addresses, and back a CSV with all the locations.

To measure these two APIs, you could send a few million requests to the API server as fast as possible, and also create an equivalent CSV file for the batch API and measure its processing time.
But what metric should you use to summarize the result?

### Metric: Elapsed time

You could measure elapsed time.
And that's probably fine for individual optimization session, where you repeatedly measure the speed of the same input.

However, to be thorough, you will want to measure multiple different inputs, and elapsed time can be problematic in this case.
Imagine you get the following result:

* 7,000-row CSV: 130 milliseconds.
* 13,000-row CSV: 237 milliseconds.

Is the speed for both files the same?
You can do some math in your head, but that is error-prone and cumbersome.

### Metric: Throughput

A better metric for batch processing is throughput, in this case addresses/second.
If I translate the elapsed time in the two files above to throughput, I get:

* 7,000-row CSV: 53,846 addresses/second.
* 13,000-row CSV: 54,852 addresses/second.

It's much easier to see that both files were processed with the approximately the same speed.

For a server handling individual API requests, throughput is useful but insufficient.
Imagine that for 1% of addresses, processing is 100× slower than the other 99% of requests.
For the batch API, this doesn't matter.
But for the server API, this means 1% of user requests will have super-slow response times, and users might not like that!
If you just measure addresses/second, these outliers will be invisible.

### Metric: Latency

For an API where you are doing many separate requests each of which needs to be fast, you often want additional metrics, the latency at different percentiles.
Latency is the time to respond to a request.
For example, you can calculate 50th, 95th, and 99th percentile latencies.

For a batch API, the latency of an individual address is irrelevant.
A user won't care how long it took to process any individual address, they just care about how long it takes until the full batch of results comes back.

### Next steps {.unnumbered}

Once you have a benchmark, you can use it to identify which specific parts of your code are slow.
I'll discuss that in the next chapter.
