# Tune your code for your compiler's quirks

Your compiler is not magic: it will have bugs, limitations, and quirks.
If you want to maximize your code's speed, you might need to take them into account.
This is of course _very_ specific to your language, compiler, and version of compiler, so these sort of optimizations can be very brittle.
Like tuning your code for a specific CPU model, consider them as a last resource.

To demonstrate, let's look at a limitation in Numba's options for looping.
We're going to look at the performance impacts of two different ways of looping over an array:

```{python}
#| echo: false
%load_ext book_magics
```

```{python}
import numpy as np
from numba import jit

@jit
def sum_direct_for(arr):
    total = 0
    for value in arr:
        total += value
    return total

@jit
def sum_indexing(arr):
    total = 0
    for i in range(len(arr)):
        total += arr[i]
    return total

DATA = np.arange(0, 1_000_000, dtype=np.uint64)
assert sum_direct_for(DATA) == sum_indexing(DATA)
```

If we compare these two functions, the second is much faster:

```{python}
#| echo: false
%%compare_timing
sum_direct_for(DATA)
sum_indexing(DATA)
```

I filed [a bug against Numba about this](https://github.com/numba/numba/issues/9210).
Hopefully it will be fixed one day, at which point you'll be able to use either idiom and get the same performance.

