# Get rid of branches with branchless programming

In general, branches can make it harder for both the compiler and CPU to generate and run your code quickly, for a number of reasons.
Some of the reasons depend on the CPU's ability to predict branches, which means you will get different performance results depending on the data:

* **Mispredicting branches in the CPU is very expensive.**
  Recall that your CPU tries to predict which branch your code will take, so it can speculatively continue with executing instructions in parallel.
  When your conditionals' outcomes are hard to predict, the CPU may speculatively execute the wrong branch, and then have to undo all that work and go back and execute the other branch.

In addition, the compiler may generate less efficient code, with slow downs that are broader and less dependent on the specific data:

* **The compiler may have harder time using auto-vectorization to generate SIMD code.**
  SIMD instructions do the same thing to multiple data values, and a branch might make it impossible to do the same thing.
  There are SIMD instructions designed to help in these situations, but there's a limit to how much they can do.
* **The compiler might have a harder time optimizing your code in general.**
  If your code has two branches, it is harder for the compiler to combine that code with previous and later code.

One solution to these problems is branchless programming, where we restructure code to get rid of branches altogether.

```{python}
import numpy as np
from numba import njit
```

```{python}
#| echo: false
%load_ext book_magics
```

## A simple example of branch misprediction

Let's see an example of code where branch misprediction slows down your code.

Imagine you're getting 16-bit images from a digital microscope, and you only care about the bright parts of the image.
Dark areas have no information, and have lots of noise.
If we want to clean those areas up, a simplistic algorithm is setting all values below a certain threshold to complete black, i.e. 0.

To test our implementations, I generated two simulated images:

```{python}
rng = np.random.default_rng(12345)
noise = rng.integers(0, high=1000, size=(4096, 4096), dtype=np.uint16)
signal = rng.integers(0, high=5000, size=(4096, 4096), dtype=np.uint16)
# A noisy, hard to predict image:
NOISY_IMAGE = noise | signal
# An image with same value, 0, for all pixels:
PREDICTABLE_IMAGE = np.zeros((4096, 4096), dtype=np.uint16)
```

Here's a first pass implementation using Numba.
We generate this with SIMD disabled to demonstrate the cost of branch misprediction:

```{python}
from book_utilities import disabled_simd

with disabled_simd() as njit_no_simd:
    @njit
    def remove_noise_naive(arr, noise_threshold):
        # Ensure noise_threshold has some data type as the values in the arr,
        # to make it as easy as possible for the compiler to find
        # optimizations.
        noise_threshold = arr.dtype.type(noise_threshold)
        result = arr.copy()
        for i in range(result.shape[0]):
            for j in range(result.shape[1]):
                if result[i, j] < noise_threshold:
                    result[i, j] = 0
        return result

    denoised = remove_noise_naive(NOISY_IMAGE, 1000)
```

Notice that whether a specific pixel is above or below the noise threshold may be difficult to predict, depending on the image.
That is certainly the case for our simulated image.

Here's how long this version takes to run:

```{python}
%%compare_timing
remove_noise_naive(NOISY_IMAGE, 1000)
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
```

### Switching to branchless programming

The key problem in the function above is the following lines:

```{python}
#| eval: false
if result[i, j] < noise_threshold:
    result[i, j] = 0
```

Depending on the value of `result[i, j]` either a value will be zeroed, or nothing will happen: a branch in the code.
If the CPU mispredicts which branch is taken, it will end up wasting lots of time undoing work on the wrong branch.

In branchless programming, we come up with a way to express the same logic in a way that doesn't involve branches.
In this case, instead of doing nothing, we can change the code so it _always_ writes a new value.
We use an arithmetic to trick to pick which value to write:

```{python}
with disabled_simd() as njit_no_simd:
    @njit
    def remove_noise_branchless_1(arr, noise_threshold):
        result = arr.copy()
        for i in range(result.shape[0]):
            for j in range(result.shape[1]):
                # false/true becomes 0 or 1 respectively when converted to a
                # number:
                above_threshold = np.uint16(result[i, j] >= noise_threshold)
                # If we're above the threshold, we keep the value, otherwise
                # the expression evaluates to 0. Either way we're writing to
                # result[i, j].
                result[i, j] = above_threshold * result[i, j]
        return result

    assert np.array_equal(
        denoised,
        remove_noise_branchless_1(NOISY_IMAGE, 1000)
    )
```

As an alternative, we can express the same thing with a ternary operator; for Numba, at least, the compiler is smart enough to turn this expression into non-branching code.

```{python}
with disabled_simd() as njit_no_simd:
    @njit
    def remove_noise_branchless_2(arr, noise_threshold):
        noise_threshold = arr.dtype.type(noise_threshold)
        result = arr.copy()
        for i in range(result.shape[0]):
            for j in range(result.shape[1]):
                value = result[i, j]
                result[i, j] = 0 if value < noise_threshold else value
        return result

    assert np.array_equal(
        denoised,
        remove_noise_branchless_2(NOISY_IMAGE, 1000)
    )
```

Here's the difference in performance:

```{python}
#| echo: false
%%compare_timing
remove_noise_naive(NOISY_IMAGE, 1000)
remove_noise_branchless_1(NOISY_IMAGE, 1000)
remove_noise_branchless_2(NOISY_IMAGE, 1000)
```

```{python}
#| echo: false
%%compare_timing
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_1(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_2(PREDICTABLE_IMAGE, 1000)
```

The two branchless versions are seemingly doing more work: they write to every pixel in the result image, not just some of them.
But that extra work is worth it, because it gets rid of an expensive branch misprediction.

### Bonus optimization: getting rid of the copy

Now that we're overwriting all the values in the result, we don't actually have to copy the original image:

```{python}
with disabled_simd() as njit_no_simd:
    @njit
    def remove_noise_branchless_3(arr, noise_threshold):
        noise_threshold = arr.dtype.type(noise_threshold)
        result = np.empty(arr.shape, dtype=arr.dtype)
        for i in range(result.shape[0]):
            for j in range(result.shape[1]):
                value = arr[i, j]
                result[i, j] = 0 if value < noise_threshold else value
        return result

    assert np.array_equal(
        denoised,
        remove_noise_branchless_3(NOISY_IMAGE, 1000)
    )
```

```{python}
#| echo: false
%%compare_timing
remove_noise_naive(NOISY_IMAGE, 1000)
remove_noise_branchless_1(NOISY_IMAGE, 1000)
remove_noise_branchless_3(NOISY_IMAGE, 1000)
```

```{python}
#| echo: false
%%compare_timing
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_1(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_3(PREDICTABLE_IMAGE, 1000)
```

### What happens if you enable SIMD?

On my computer, which has an x86-64 CPU with support for AVX2 SIMD instructions, the naive version gets slower.
Sometimes the compiler's auto-vectorization just makes things worse.
However, the branchless versions gets even faster with SIMD enabled:

```{python}
@njit
def remove_noise_naive_simd(arr, noise_threshold):
    noise_threshold = arr.dtype.type(noise_threshold)
    result = arr.copy()
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            if result[i, j] < noise_threshold:
                result[i, j] = 0
    return result

@njit
def remove_noise_branchless_3_simd(arr, noise_threshold):
    noise_threshold = arr.dtype.type(noise_threshold)
    result = np.empty(arr.shape, dtype=arr.dtype)
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            value = arr[i, j]
            result[i, j] = 0 if value < noise_threshold else value
    return result

assert np.array_equal(
    denoised,
    remove_noise_naive_simd(NOISY_IMAGE, 1000)
)
assert np.array_equal(
    denoised,
    remove_noise_branchless_3_simd(NOISY_IMAGE, 1000)
)
```

```{python}
#| echo: false
%%compare_timing
remove_noise_naive(NOISY_IMAGE, 1000)
remove_noise_naive_simd(NOISY_IMAGE, 1000)
remove_noise_branchless_3(NOISY_IMAGE, 1000)
remove_noise_branchless_3_simd(NOISY_IMAGE, 1000)
```

```{python}
#| echo: false
%%compare_timing
remove_noise_naive(PREDICTABLE_IMAGE, 1000)
remove_noise_naive_simd(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_3(PREDICTABLE_IMAGE, 1000)
remove_noise_branchless_3_simd(PREDICTABLE_IMAGE, 1000)
```

## Branchless programming with more than two branches

Let's consider a slightly more complex example, where we have three different branches.
We have a time series of numbers, and want to record how many times values went up, stayed the same, or went down compared to the previous value.

```{python}
@njit
def count_sequences(arr):
    DECREASE, UNCHANGED, INCREASE = 1, 2, 3
    prev_value = 0
    prev_status = UNCHANGED
    decreased = 0
    increased = 0
    unchanged = 0
    for i in range(len(arr)):
        value = arr[i]
        if value > prev_value:
            status = INCREASE
        elif value == prev_value:
            status = UNCHANGED
        else:
            status = DECREASE
        if status != prev_status:
            if status == INCREASE:
                increased += 1
            elif status == UNCHANGED:
                unchanged += 1
            else:
                decreased += 1
        prev_status = status
        prev_value = value
    return decreased, unchanged, increased
```

For example, we expect this to to have 2 increasing, 1 unchanged, and 1 decreasing sequences:

```{python}
print(count_sequences([1, 2, 3, 2, 2, 4]))
```

We can run this on data that is always increasing, which means branch prediction will work well, and randomized data where branch prediction is impossible:

```{python}
# Increases linearly from 1 to 1,000,000:
PREDICTABLE_DATA = np.linspace(1, 1_000_000, 1_000_000, dtype=np.uint64)
# Shuffled randomly:
SHUFFLED_DATA = PREDICTABLE_DATA.copy()
np.random.shuffle(SHUFFLED_DATA)
```

```{python}
#| echo: false
%%compare_timing
count_sequences(PREDICTABLE_DATA)
count_sequences(SHUFFLED_DATA)
```

As you can see, random data results in much slower execution even though the number of CPU instruction should be basically the same.
The problem: branch misprediction.

### Simplifying the logic with result indexing

Instead of having different variables for the results, we can use an array; this enables us to use indexing to choose where to put the result.
We still have unpredictable branches, but the code is easier to reason about:

```{python}
@njit
def count_sequences_2(arr):
    # We'll use these as indexes into the result array:
    DECREASE, UNCHANGED, INCREASE = 0, 1, 2
    prev_value = 0
    prev_status = UNCHANGED
    result = np.zeros((3,), dtype=np.uint64)

    for i in range(len(arr)):
        value = arr[i]
        if value > prev_value:
            status = INCREASE
        elif value == prev_value:
            status = UNCHANGED
        else:
            status = DECREASE
        if status != prev_status:
            result[status] += 1
        prev_status = status
        prev_value = value
    return result[0], result[1], result[2]

assert np.array_equal(
    count_sequences(SHUFFLED_DATA),
    count_sequences_2(SHUFFLED_DATA)
)
```

```{python}
#| echo: false
%%compare_timing
count_sequences(PREDICTABLE_DATA)
count_sequences_2(PREDICTABLE_DATA)
```

```{python}
#| echo: false
%%compare_timing
count_sequences(SHUFFLED_DATA)
count_sequences_2(SHUFFLED_DATA)
```

### Switching to branchless code

Since we don't want branches, we want the same code to run every time, no matter what:

```{python}
@njit
def count_sequences_branchless_1(arr):
    DECREASE, UNCHANGED, INCREASE = 0, 1, 2
    prev_value = 0
    prev_status = UNCHANGED
    result = np.zeros((3,), dtype=np.uint64)

    for i in range(len(arr)):
        value = arr[i]
        #status = INCREASE if value > prev_value else UNCHANGED
        #status = DECREASE if value < prev_value else status
        status = 1 + int(value > prev_value) - int(value < prev_value)
        result[status] += 1 if status != prev_status else 0
        prev_status = status
        prev_value = value
    return result[0], result[1], result[2]

assert np.array_equal(
    count_sequences(SHUFFLED_DATA),
    count_sequences_branchless_1(SHUFFLED_DATA)
)
```

```{python}
#| echo: false
%%compare_timing
count_sequences(PREDICTABLE_DATA)
count_sequences_branchless_1(PREDICTABLE_DATA)
```

```{python}
#| echo: false
%%compare_timing
count_sequences(SHUFFLED_DATA)
count_sequences_branchless_1(SHUFFLED_DATA)
```

By getting rid of branches, we've signifcantly sped up the `SHUFFLED_DATA` case.
The `PREDICTABLE_DATA` case is slower, which is a common outcome of branchless programming: we're doing more work on every iteration, since we can't shortcut out with a branch.
However, what is less expected is that `count_sequences_branchless_1(PREDICTABLE_DATA)` runs much slower than `count_sequences_branchless_1(SHUFFLED_DATA)`.
This can't be because of branch prediction, though, since we've gotten rid of all the branches!

Can you figure out what is causing the difference in performance?

### Fixing our inconsistent performance

The reason our latest version is slower on `PREDICTABLE_DATA` is that `result[INCREASE]` has become a data dependency.
It gets written to in every loop iteration, because `PREDITABLE_DATA`'s has continuously increasing time series.
That means the CPU can't use instruction-level parallelism to do multiple iterations of the loop in parallel.
For `SHUFFLED_DATA` this is less of a problem because loop iterations don't always write to the same place: sometimes the sequence increases, sometimes it decreases.

We can fix, or at least reduce, the data dependency problem by having multiple accumulators:

```{python}
@njit
def count_sequences_branchless_2(arr):
    DECREASE, UNCHANGED, INCREASE = 0, 1, 2
    prev_value = 0
    prev_status = UNCHANGED
    result = np.zeros((3,8), dtype=np.uint64)

    for i in range(len(arr)):
        value = arr[i]
        status = INCREASE if value > prev_value else UNCHANGED
        status = DECREASE if value < prev_value else status
        #status = 1 + int(value > prev_value) - int(value < prev_value)
        result[status, i % 8] += 1 if status != prev_status else 0
        prev_status = status
        prev_value = value
    return result[0].sum(), result[1].sum(), result[2].sum()

assert np.array_equal(
    count_sequences(SHUFFLED_DATA),
    count_sequences_branchless_2(SHUFFLED_DATA)
)
```

```{python}
#| echo: false
%%compare_timing
count_sequences(PREDICTABLE_DATA)
count_sequences_branchless_2(PREDICTABLE_DATA)
```

```{python}
#| echo: false
%%compare_timing
count_sequences(SHUFFLED_DATA)
count_sequences_branchless_2(SHUFFLED_DATA)
```

Our latest code now has consistent performance for different inputs.
And for cases where the time series isn't predictable, it runs 3.5× as fast as the original version.

## When should you use branchless programming?

TODO May not be necessary depending on the SIMD instructions you have available.
If you're using SIMD the compiler has removed the branches so branch prediction is irrelevant.

TODO For branch prediction purposes, Whether or not branchless code is actually faster depends on the specific data and how predictable the branches are!
Need to measure with real, or realistic, data that will match predictability.
Consider whether consistent outcomes are more important than speed of the likely case.

## Understand what counts as a branch

TODO comparisons don't count, it's about different code paths being run

TODO for loops

TODO Subtle point that we're relying on the compiler to notice the `A if Y else B` pattern it can execute both A and B. short circuiting typically means it won't. demonstrate how a complex/side-effecty A can break the code and how to work around it.

## Hidden sources of branching

In addition to explicit branches you might add to your code, there are other less obvious sources of branching that can be added by the compiler, including handling division by zero and bounds checking.

Dividing by zero is mathematically meaningless, so programming languages need to decide how to handle it for different data types.
For example, in Python you get a `ZeroDivisionError` by default, whereas NumPy floats return the special value `inf`/`-inf`/`nan` when divided by zero (for positive numbers, negative numbers, and zero, respectively).

If your programming language has any sort of graceful handling for divide by zero, behind the scenes that will require generating an `if` statement any time division by a variable happens.
Numba, for example, will raise a `ZeroDivisionError` by default.

Another potential source of auto-generated branches is bounds checking, which we will discuss in a later chapter.
